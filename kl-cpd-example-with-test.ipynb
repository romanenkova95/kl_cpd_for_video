{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from utils import datasets, kl_cpd, models, metrics\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal sampling is impossible, do random sampling.\n"
     ]
    }
   ],
   "source": [
    "experiments_name = 'explosion'\n",
    "train_dataset, test_dataset = datasets.CPDDatasets(experiments_name=experiments_name).get_dataset_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['wnd_dim'] = 4\n",
    "args['RNN_hid_dim'] = 16\n",
    "args['batch_size'] = 4\n",
    "args['lr'] = 1e-4\n",
    "args['weight_decay'] = 0.\n",
    "args['grad_clip'] = 10\n",
    "args['CRITIC_ITERS'] = 5\n",
    "args['weight_clip'] = .1\n",
    "args['lambda_ae'] = 0.1 #0.001\n",
    "args['lambda_real'] = 10 #0.1\n",
    "args['num_layers'] = 1\n",
    "args['data_dim'] = 12288\n",
    "args['emb_dim'] = 100\n",
    "\n",
    "args['window_1'] = 4\n",
    "args['window_2'] = 4\n",
    "\n",
    "args['sqdist'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/eromanenkova/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | netG      | NetG       | 1.4 M \n",
      "1 | netD      | NetD       | 2.5 M \n",
      "2 | extractor | Sequential | 2.0 M \n",
      "-----------------------------------------\n",
      "4.0 M     Trainable params\n",
      "2.0 M     Non-trainable params\n",
      "6.0 M     Total params\n",
      "23.865    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ddce309297436da4da30ceaf0a43d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping threshold reached: val_mmd2_real_D = 7.558020181930303e-11 < 1e-05. Signaling Trainer to stop.\n",
      "  0%|                                                                                                                                                | 0/27 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'po' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m threshold_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mthreshold_list))\n\u001b[1;32m     39\u001b[0m threshold_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.001\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(threshold_list) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1.001\u001b[39m]\n\u001b[0;32m---> 42\u001b[0m _, delay_list, fp_delay_list \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkl_cpd_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mkl_cpd_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mthreshold_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mklcpd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m    \n\u001b[1;32m     50\u001b[0m path_to_saves \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     51\u001b[0m metrics\u001b[38;5;241m.\u001b[39mwrite_metrics_to_file(path_to_saves \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_metrics.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, _, name)    \n",
      "File \u001b[0;32m~/kl_cpd_for_video/utils/metrics.py:261\u001b[0m, in \u001b[0;36mevaluation_pipeline\u001b[0;34m(model, test_dataloader, threshold_list, device, verbose, model_type, subseq_len)\u001b[0m\n\u001b[1;32m    250\u001b[0m confusion_matrix_dict \u001b[38;5;241m=\u001b[39m {}    \n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m tqdm(threshold_list):\n\u001b[1;32m    253\u001b[0m     (\n\u001b[1;32m    254\u001b[0m         TN,\n\u001b[1;32m    255\u001b[0m         FP,\n\u001b[1;32m    256\u001b[0m         FN,\n\u001b[1;32m    257\u001b[0m         TP,\n\u001b[1;32m    258\u001b[0m         mean_delay,\n\u001b[1;32m    259\u001b[0m         mean_fp_delay,\n\u001b[1;32m    260\u001b[0m         cover\n\u001b[0;32m--> 261\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_metrics_on_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     confusion_matrix_dict[threshold] \u001b[38;5;241m=\u001b[39m (TN, FP, FN, TP)\n\u001b[1;32m    265\u001b[0m     delay_dict[threshold] \u001b[38;5;241m=\u001b[39m mean_delay\n",
      "File \u001b[0;32m~/kl_cpd_for_video/utils/metrics.py:94\u001b[0m, in \u001b[0;36mevaluate_metrics_on_set\u001b[0;34m(model, test_loader, threshold, verbose, model_type, subseq_len, device)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_inputs, test_labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m---> 94\u001b[0m         test_out, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_models_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43msubseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m             test_out \u001b[38;5;241m=\u001b[39m test_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/kl_cpd_for_video/utils/metrics.py:68\u001b[0m, in \u001b[0;36mget_models_predictions\u001b[0;34m(inputs, labels, model, model_type, subseq_len, device)\u001b[0m\n\u001b[1;32m     66\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     67\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 68\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mklcpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_klcpd_output_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs, true_labels\n",
      "File \u001b[0;32m~/kl_cpd_for_video/utils/kl_cpd.py:326\u001b[0m, in \u001b[0;36mget_klcpd_output_2\u001b[0;34m(kl_cpd_model, batch, window)\u001b[0m\n\u001b[1;32m    320\u001b[0m pred_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(pred_out)\u001b[38;5;241m.\u001b[39mto(kl_cpd_model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m#TODO fix    \u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m#pred_out = pred_out / pred_out.max(1).values.expand(pred_out.shape[1], pred_out.shape[0]).transpose(0, 1)    \u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m#TODO check\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m#pred_out = pred_out / pred_out.norm(1, keepdim=True)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m#pred_out = torch.tanh(pred_out)\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m pred_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[43mpo\u001b[49m\u001b[38;5;241m/\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmax(po, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m#pred_out = torch.tanh(pred_out * 10 ** 7)\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred_out\n",
      "\u001b[0;31mNameError\u001b[0m: name 'po' is not defined"
     ]
    }
   ],
   "source": [
    "for name in ['x3d_m']:\n",
    "    extractor = torch.hub.load('facebookresearch/pytorchvideo:main', name, pretrained=True)\n",
    "    extractor = nn.Sequential(*list(extractor.blocks[:5]))\n",
    "    \n",
    "    seed = 102\n",
    "    models.fix_seeds(seed)\n",
    "    experiments_name = ('explosion')\n",
    "\n",
    "    netG = models.NetG(args)\n",
    "    netD = models.NetD(args)\n",
    "\n",
    "    kl_cpd_model = models.KLCPDVideo(netG, netD, args, train_dataset=train_dataset, test_dataset=test_dataset, \n",
    "                                     extractor=extractor)\n",
    "    \n",
    "    logger = TensorBoardLogger(save_dir='logs/explosion', name='kl_cpd')\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_mmd2_real_D\", stopping_threshold=1e-5, \n",
    "                                        verbose=True, mode=\"min\", patience=5)\n",
    "\n",
    "    for param in kl_cpd_model.extractor.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        gpus='1',\n",
    "        benchmark=True,\n",
    "        check_val_every_n_epoch=1,\n",
    "        gradient_clip_val=args['grad_clip'],\n",
    "        logger=logger,\n",
    "        callbacks=early_stop_callback\n",
    "    )\n",
    "\n",
    "    trainer.fit(kl_cpd_model)\n",
    "    torch.save(kl_cpd_model.state_dict(), 'model_' + name + '.pth')    \n",
    "    \n",
    "    threshold_number = 25\n",
    "    threshold_list = np.linspace(-5, 5, threshold_number)\n",
    "    threshold_list = 1 / (1 + np.exp(-threshold_list))\n",
    "    threshold_list = [-0.001] + list(threshold_list) + [1.001]\n",
    "    \n",
    "    \n",
    "    _, delay_list, fp_delay_list = metrics.evaluation_pipeline(kl_cpd_model, \n",
    "                                                           kl_cpd_model.val_dataloader(),  \n",
    "                                                           threshold_list, \n",
    "                                                           device='cuda', \n",
    "                                                           model_type='klcpd',\n",
    "                                                           verbose=False)    \n",
    "\n",
    "\n",
    "    path_to_saves = ''\n",
    "    metrics.write_metrics_to_file(path_to_saves + 'result_metrics.txt', _, name)    \n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.plot(fp_delay_list.values(), delay_list.values(), '-o', markersize=8, label='TSCP')\n",
    "    plt.xlabel('Mean Time to False Alarm', fontsize=28)\n",
    "    plt.ylabel('Mean Detection Delay', fontsize=28)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.legend(loc='upper left', fontsize=26);        \n",
    "    plt.savefig('saves/figure_' + str(name) + '.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
